{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import cPickle as pickle\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albumin', 'Arterial_BE', 'Arterial_lactate', 'Arterial_pH', 'BUN', 'CO2_mEqL', 'Calcium', 'Chloride', 'Creatinine', 'DiaBP', 'FiO2_1', 'GCS', 'Glucose', 'HCO3', 'HR', 'Hb', 'INR', 'Ionised_Ca', 'Magnesium', 'MeanBP', 'PT', 'PTT', 'PaO2_FiO2', 'Platelets_count', 'Potassium', 'RR', 'SGOT', 'SGPT', 'SIRS', 'SOFA', 'Shock_Index', 'Sodium', 'SpO2', 'SysBP', 'Temp_C', 'Total_bili', 'WBC_count', 'Weight_kg', 'age', 'elixhauser', 'gender', 'mechvent', 'output_4hourly', 'output_total', 'paCO2', 'paO2', 're_admission', 'bloc']\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "with open('../data/state_features.txt') as f:\n",
    "    state_features = f.read().split()\n",
    "print (state_features)\n",
    "print len(state_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rl_train_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bloc</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>elixhauser</th>\n",
       "      <th>re_admission</th>\n",
       "      <th>died_in_hosp</th>\n",
       "      <th>mortality_90d</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>...</th>\n",
       "      <th>median_dose_vaso</th>\n",
       "      <th>max_dose_vaso</th>\n",
       "      <th>input_total_tev</th>\n",
       "      <th>input_4hourly_tev</th>\n",
       "      <th>output_total</th>\n",
       "      <th>output_4hourly</th>\n",
       "      <th>cumulated_balance_tev</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>7245052800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.797351</td>\n",
       "      <td>0.939195</td>\n",
       "      <td>0.589916</td>\n",
       "      <td>0.750908</td>\n",
       "      <td>0.554500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.222560</td>\n",
       "      <td>3</td>\n",
       "      <td>7245067200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.831780</td>\n",
       "      <td>0.934543</td>\n",
       "      <td>0.674384</td>\n",
       "      <td>0.819589</td>\n",
       "      <td>0.580033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.657321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.356608</td>\n",
       "      <td>3</td>\n",
       "      <td>7245081600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833222</td>\n",
       "      <td>0.656575</td>\n",
       "      <td>0.765423</td>\n",
       "      <td>0.939329</td>\n",
       "      <td>0.555033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.367788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452837</td>\n",
       "      <td>3</td>\n",
       "      <td>7245096000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.834033</td>\n",
       "      <td>0.603831</td>\n",
       "      <td>0.783597</td>\n",
       "      <td>0.847073</td>\n",
       "      <td>0.545700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.199099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.527957</td>\n",
       "      <td>3</td>\n",
       "      <td>7245110400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.834836</td>\n",
       "      <td>0.603831</td>\n",
       "      <td>0.794059</td>\n",
       "      <td>0.811583</td>\n",
       "      <td>0.539533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.057596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bloc  icustayid   charttime  gender       age  elixhauser  \\\n",
       "0  0.000000          3  7245052800     0.0  0.412568         0.0   \n",
       "1  0.222560          3  7245067200     0.0  0.412568         0.0   \n",
       "2  0.356608          3  7245081600     0.0  0.412568         0.0   \n",
       "3  0.452837          3  7245096000     0.0  0.412568         0.0   \n",
       "4  0.527957          3  7245110400     0.0  0.412568         0.0   \n",
       "\n",
       "   re_admission  died_in_hosp  mortality_90d  Weight_kg    ...     \\\n",
       "0           0.0             0              1   0.262712    ...      \n",
       "1           0.0             0              1   0.262712    ...      \n",
       "2           0.0             0              1   0.262712    ...      \n",
       "3           0.0             0              1   0.262712    ...      \n",
       "4           0.0             0              1   0.262712    ...      \n",
       "\n",
       "   median_dose_vaso  max_dose_vaso  input_total_tev  input_4hourly_tev  \\\n",
       "0               0.0            0.0         0.797351           0.939195   \n",
       "1               0.0            0.0         0.831780           0.934543   \n",
       "2               0.0            0.0         0.833222           0.656575   \n",
       "3               0.0            0.0         0.834033           0.603831   \n",
       "4               0.0            0.0         0.834836           0.603831   \n",
       "\n",
       "   output_total  output_4hourly  cumulated_balance_tev  vaso_input  iv_input  \\\n",
       "0      0.589916        0.750908               0.554500         0.0       4.0   \n",
       "1      0.674384        0.819589               0.580033         0.0       4.0   \n",
       "2      0.765423        0.939329               0.555033         0.0       2.0   \n",
       "3      0.783597        0.847073               0.545700         0.0       2.0   \n",
       "4      0.794059        0.811583               0.539533         0.0       2.0   \n",
       "\n",
       "     reward  \n",
       "0  0.125000  \n",
       "1  0.657321  \n",
       "2  1.367788  \n",
       "3  1.199099  \n",
       "4  1.057596  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('../data/rl_val_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/rl_test_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define an action mapping - how to get an id representing the action from the (iv,vaso) tuple\n",
    "action_map = {}\n",
    "count = 0\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        action_map[(iv,vaso)] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_action_map = {}\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        inv_action_map[5*iv+vaso] = [iv,vaso]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in the actions from the q network\n",
    "q_net_save_dir = '../continuous/dqn_normal/'\n",
    "train_actions = pickle.load(open( q_net_save_dir + \"dqn_normal_actions_train.p\", \"rb\" ))\n",
    "val_actions = pickle.load(open( q_net_save_dir + \"dqn_normal_actions_val.p\", \"rb\" ))\n",
    "test_actions = pickle.load(open( q_net_save_dir + \"dqn_normal_actions_test.p\", \"rb\" ))\n",
    "\n",
    "df['agent_actions'] = train_actions\n",
    "df['agent_iv'] = df['agent_actions'].apply(lambda x:inv_action_map[x][0] )\n",
    "df['agent_vaso'] = df['agent_actions'].apply(lambda x:inv_action_map[x][1] )\n",
    "\n",
    "val_df['agent_actions'] = val_actions\n",
    "val_df['agent_iv'] = val_df['agent_actions'].apply(lambda x:inv_action_map[x][0] )\n",
    "val_df['agent_vaso'] = val_df['agent_actions'].apply(lambda x:inv_action_map[x][1] )\n",
    "\n",
    "test_df['agent_actions'] = test_actions\n",
    "test_df['agent_iv'] = test_df['agent_actions'].apply(lambda x:inv_action_map[x][0] )\n",
    "test_df['agent_vaso'] = test_df['agent_actions'].apply(lambda x:inv_action_map[x][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess the actions so that they are zero mean\n",
    "df['iv_input'] = df['iv_input'].apply(lambda x: x/4.0)\n",
    "df['vaso_input'] = df['vaso_input'].apply(lambda x: x/4.0)\n",
    "\n",
    "val_df['iv_input'] = val_df['iv_input'].apply(lambda x: x/4.0)\n",
    "val_df['vaso_input'] = val_df['vaso_input'].apply(lambda x: x/4.0)\n",
    "\n",
    "test_df['iv_input'] = test_df['iv_input'].apply(lambda x: x/4.0)\n",
    "test_df['vaso_input'] = test_df['vaso_input'].apply(lambda x: x/4.0)\n",
    "\n",
    "df['agent_iv'] = df['agent_iv'].apply(lambda x: x/4.0)\n",
    "df['agent_vaso'] = df['agent_vaso'].apply(lambda x: x/4.0)\n",
    "\n",
    "val_df['agent_iv'] = val_df['agent_iv'].apply(lambda x: x/4.0)\n",
    "val_df['agent_vaso'] = val_df['agent_vaso'].apply(lambda x: x/4.0)\n",
    "\n",
    "test_df['agent_iv'] = test_df['agent_iv'].apply(lambda x: x/4.0)\n",
    "test_df['agent_vaso'] = test_df['agent_vaso'].apply(lambda x: x/4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Gaussian noise to the state features\n",
    "gaussian_shape = df.loc[:, state_features].values.shape\n",
    "noise = np.random.normal(0, 0.03, gaussian_shape)\n",
    "df.loc[:, state_features] += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_1_size = 500\n",
    "hidden_2_size = 500\n",
    "class EnvModel():\n",
    "    def __init__(self):\n",
    "        self.phase = tf.placeholder(tf.bool)\n",
    "        \n",
    "        self.input_size = len(state_features)\n",
    "\n",
    "        self.cur_state = tf.placeholder(tf.float32, shape=[None, self.input_size],name=\"cur_state\")\n",
    "        self.next_state = tf.placeholder(tf.float32, shape=[None, self.input_size],name=\"next_state\")\n",
    "        \n",
    "        self.done_flags = tf.placeholder(tf.int32, shape=[None], name=\"done_flags\")\n",
    "        \n",
    "        self.actions = tf.placeholder(tf.int32, shape = [None, 2], name=\"actions\")\n",
    "        \n",
    "        self.input = tf.concat([self.cur_state, tf.cast(self.actions, tf.float32)], axis=1)\n",
    "        \n",
    "        self.target = self.next_state - self.cur_state\n",
    "\n",
    "        self.fc_1 = tf.contrib.layers.fully_connected(self.input, hidden_1_size, activation_fn=tf.nn.relu)\n",
    "        self.fc_1_bn = tf.contrib.layers.batch_norm(self.fc_1, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_2 = tf.contrib.layers.fully_connected(self.fc_1_bn, hidden_2_size, activation_fn=tf.nn.relu)\n",
    "        self.fc_2_bn = tf.contrib.layers.batch_norm(self.fc_2, center=True, scale=True, is_training=self.phase)\n",
    "        \n",
    "        self.output = tf.contrib.layers.fully_connected(self.fc_2_bn, self.input_size, activation_fn = None)\n",
    "        \n",
    "        self.multiplier = tf.expand_dims(1 -self.done_flags, 1)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.multiply(tf.square(self.target-self.output), tf.cast(self.multiplier, tf.float32)))  \n",
    "        \n",
    "        self.est_next_state = self.output + self.cur_state\n",
    "\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(self.update_ops):\n",
    "        # Ensures that we execute the update_ops before performing the model update, so batchnorm works\n",
    "            self.update_model = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_train_batch(size):\n",
    "    a = df.sample(n=size)\n",
    "    states = None\n",
    "    actions = None\n",
    "    rewards = None\n",
    "    next_states = None\n",
    "    done_flags = None\n",
    "    for i in a.index:\n",
    "        cur_state = a.ix[i,state_features]\n",
    "        iv = int(a.ix[i, 'iv_input'])\n",
    "        vaso = int(a.ix[i, 'vaso_input'])\n",
    "        action = np.array([iv,vaso])\n",
    "\n",
    "        if i != df.index[-1]:\n",
    "            # if not terminal step in trajectory             \n",
    "            if df.ix[i, 'icustayid'] == df.ix[i+1, 'icustayid']:\n",
    "                next_state = df.ix[i + 1, state_features]\n",
    "                done = 0\n",
    "            else:\n",
    "                # trajectory is finished\n",
    "                next_state = np.zeros(len(cur_state))\n",
    "                done = 1\n",
    "        else:\n",
    "            # last entry in df is the final state of that trajectory\n",
    "            next_state = np.zeros(len(cur_state))\n",
    "            done = 1\n",
    "\n",
    "        if states is None:\n",
    "            states = copy.deepcopy(cur_state)\n",
    "        else:\n",
    "            states = np.vstack((states,cur_state))\n",
    "\n",
    "        if actions is None:\n",
    "            actions = [action]\n",
    "        else:\n",
    "            actions = np.vstack((actions,action))\n",
    "\n",
    "        if next_states is None:\n",
    "            next_states = copy.deepcopy(next_state)\n",
    "        else:\n",
    "            next_states = np.vstack((next_states,next_state))\n",
    "\n",
    "        if done_flags is None:\n",
    "            done_flags = [done]\n",
    "        else:\n",
    "            done_flags = np.vstack((done_flags,done))\n",
    "    \n",
    "    return (states, np.squeeze(actions), next_states, np.squeeze(done_flags), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract chunks of length size from the relevant dataframe, and yield these to the caller\n",
    "# final tells us if we want to use AGENT actions, not physician actions\n",
    "def process_eval_batch(size, eval_type = None, final=False):\n",
    "    if eval_type is None:\n",
    "        raise Exception('Provide eval_type to process_eval_batch')\n",
    "    elif eval_type == 'train':\n",
    "        a = df.copy()\n",
    "    elif eval_type == 'val':\n",
    "        a = val_df.copy()\n",
    "    elif eval_type == 'test':\n",
    "        a = test_df.copy()\n",
    "    else:\n",
    "        raise Exception('Unknown eval_type')\n",
    "    count = 0\n",
    "    while count < len(a.index):\n",
    "        states = None\n",
    "        actions = None\n",
    "        rewards = None\n",
    "        next_states = None\n",
    "        done_flags = None\n",
    "\n",
    "        start_idx = count\n",
    "        end_idx = min(len(a.index), count+size)\n",
    "        segment = a.index[start_idx:end_idx]\n",
    "        \n",
    "        for i in segment:\n",
    "            cur_state = a.ix[i,state_features]\n",
    "            \n",
    "            if not final:\n",
    "                iv = int(a.ix[i, 'iv_input'])\n",
    "                vaso = int(a.ix[i, 'vaso_input'])\n",
    "                action = np.array([iv,vaso])\n",
    "            else:\n",
    "                iv = int(a.ix[i, 'agent_iv'])\n",
    "                vaso = int(a.ix[i, 'agent_vaso'])\n",
    "                action = np.array([iv,vaso])\n",
    "            reward = a.ix[i,'reward']\n",
    "\n",
    "            if i != a.index[-1]:\n",
    "                # if not terminal step in trajectory             \n",
    "                if a.ix[i, 'icustayid'] == a.ix[i+1, 'icustayid']:\n",
    "                    next_state = a.ix[i + 1, state_features]\n",
    "                    done = 0\n",
    "                else:\n",
    "                    # trajectory is finished\n",
    "                    next_state = np.zeros(len(cur_state))\n",
    "                    done = 1\n",
    "            else:\n",
    "                # last entry in df is the final state of that trajectory\n",
    "                next_state = np.zeros(len(cur_state))\n",
    "                done = 1\n",
    "\n",
    "            if states is None:\n",
    "                states = copy.deepcopy(cur_state)\n",
    "            else:\n",
    "                states = np.vstack((states,cur_state))\n",
    "\n",
    "            if actions is None:\n",
    "                actions = [action]\n",
    "            else:\n",
    "                actions = np.vstack((actions,action))\n",
    "\n",
    "            if next_states is None:\n",
    "                next_states = copy.deepcopy(next_state)\n",
    "            else:\n",
    "                next_states = np.vstack((next_states,next_state))\n",
    "\n",
    "            if done_flags is None:\n",
    "                done_flags = [done]\n",
    "            else:\n",
    "                done_flags = np.vstack((done_flags,done))\n",
    "\n",
    "        yield (states, np.squeeze(actions), next_states, np.squeeze(done_flags), a)\n",
    "        \n",
    "        count += size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_eval(eval_type, final=False):\n",
    "    gen = process_eval_batch(size = 1000, eval_type=eval_type, final=final)\n",
    "\n",
    "    error_ret = 0\n",
    "    est_next_states = []\n",
    "\n",
    "    for b in gen:\n",
    "\n",
    "        states,actions,next_states, done_flags, _ = b\n",
    "\n",
    "        est_next_state,loss = sess.run([env_model.est_next_state,env_model.loss], \\\n",
    "            feed_dict={env_model.cur_state:states,\n",
    "                       env_model.next_state:next_states, \n",
    "                       env_model.actions:actions,\n",
    "                       env_model.done_flags:done_flags,\n",
    "                       env_model.phase:False})    \n",
    "        error_ret += loss\n",
    "        est_next_states.append(est_next_state)\n",
    "  \n",
    "    return np.array(est_next_states), error_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # Don't use all GPUs \n",
    "config.allow_soft_placement = True  # Enable manual control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_save_results():\n",
    "    # get the estimated next states UNDER THE AGENT POLICY based on the trained environment model\n",
    "    est_next_states_train, _ = do_eval(eval_type = 'train', final=True)        \n",
    "    est_next_states_val, _ = do_eval(eval_type = 'val', final=True)        \n",
    "    est_next_states_test, _ = do_eval(eval_type = 'test', final=True)   \n",
    "    \n",
    "    # save everything for later - they're used in policy evaluation and when generating plots\n",
    "    with open(save_dir + 'est_next_states_train.p', 'wb') as f:\n",
    "        pickle.dump(est_next_states_train, f)\n",
    "    with open(save_dir + 'est_next_states_val.p', 'wb') as f:\n",
    "        pickle.dump(est_next_states_val, f)\n",
    "    with open(save_dir + 'est_next_states_test.p', 'wb') as f:\n",
    "        pickle.dump(est_next_states_test, f)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load model...\n",
      "Model restored\n",
      "Init done\n",
      "Calling do save results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "# The main training loop is here\n",
    "batch_size = 32\n",
    "num_steps = 60000 # How many steps to train for\n",
    "load_model = True #Whether to load a saved model.\n",
    "save_dir = \"./env_model_regression/\"\n",
    "save_path = \"./env_model_regression/ckpt\"#The path to save our model to.rk\n",
    "tf.reset_default_graph()\n",
    "env_model = EnvModel()\n",
    "save_results = True\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    if load_model == True:\n",
    "        print('Trying to load model...')\n",
    "        try:\n",
    "            restorer = tf.train.import_meta_graph(save_path + '.meta')\n",
    "            restorer.restore(sess, tf.train.latest_checkpoint(save_dir))\n",
    "            print \"Model restored\"\n",
    "        except IOError:\n",
    "            print \"No previous model found, running default init\"\n",
    "            sess.run(init)\n",
    "    else:\n",
    "        print(\"Running default init\")\n",
    "        sess.run(init)\n",
    "    print(\"Init done\")\n",
    "    \n",
    "    net_loss = 0.0\n",
    "    for i in range(num_steps):\n",
    "        if save_results:\n",
    "            print \"Calling do save results\"\n",
    "            do_save_results()\n",
    "            break\n",
    "        \n",
    "        states,actions,next_states, done_flags, sampled_df = process_train_batch(batch_size)\n",
    "\n",
    "        # Train with the batch\n",
    "        _,loss = sess.run([env_model.update_model,env_model.loss], \\\n",
    "            feed_dict={env_model.cur_state:states,\n",
    "                       env_model.next_state:next_states, \n",
    "                       env_model.actions:actions,\n",
    "                       env_model.done_flags:done_flags,\n",
    "                       env_model.phase:True})\n",
    "\n",
    "        net_loss += loss\n",
    "    \n",
    "        \n",
    "        if i % 1000 == 0 and i > 0:\n",
    "            saver.save(sess,save_path)\n",
    "            print(\"Saved Model, step is \" + str(i))\n",
    "            \n",
    "            av_loss = net_loss/(1000.0 * batch_size)\n",
    "            print(\"Average loss is \", av_loss)\n",
    "            net_loss = 0.0\n",
    "        \n",
    "        if (i % 5000==0) and i > 0:\n",
    "            # run an evaluation on the validation set\n",
    "            _, error = do_eval(eval_type = 'val')        \n",
    "            print error\n",
    "            if (i % 30000==0) and i > 0:\n",
    "                print \"Saving results\"\n",
    "                do_save_results()\n",
    "    do_save_results()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
