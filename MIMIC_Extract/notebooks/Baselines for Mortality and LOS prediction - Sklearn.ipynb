{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import copy, math, os, pickle, time, pandas as pd, numpy as np, scipy.stats as ss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import torch, torch.utils.data as utils, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILEPATH     = '/scratch/mmd/mimic_data/final/grouping_5/all_hourly_data.h5'\n",
    "RAW_DATA_FILEPATH = '/scratch/mmd/mimic_data/final/nogrouping_5/all_hourly_data.h5'\n",
    "GAP_TIME          = 6  # In hours\n",
    "WINDOW_SIZE       = 24 # In hours\n",
    "SEED              = 1\n",
    "ID_COLS           = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "GPU               = '2'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DictDist():\n",
    "    def __init__(self, dict_of_rvs): self.dict_of_rvs = dict_of_rvs\n",
    "    def rvs(self, n):\n",
    "        a = {k: v.rvs(n) for k, v in self.dict_of_rvs.items()}\n",
    "        out = []\n",
    "        for i in range(n): out.append({k: vs[i] for k, vs in a.items()})\n",
    "        return out\n",
    "    \n",
    "class Choice():\n",
    "    def __init__(self, options): self.options = options\n",
    "    def rvs(self, n): return [self.options[i] for i in ss.randint(0, len(self.options)).rvs(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data_full_lvl2 = pd.read_hdf(DATA_FILEPATH, 'vitals_labs')\n",
    "data_full_raw  = pd.read_hdf(RAW_DATA_FILEPATH, 'vitals_labs') \n",
    "statics        = pd.read_hdf(DATA_FILEPATH, 'patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_lvl2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_imputer(df):\n",
    "    idx = pd.IndexSlice\n",
    "    df = df.copy()\n",
    "    if len(df.columns.names) > 2: df.columns = df.columns.droplevel(('label', 'LEVEL1', 'LEVEL2'))\n",
    "    \n",
    "    df_out = df.loc[:, idx[:, ['mean', 'count']]]\n",
    "    icustay_means = df_out.loc[:, idx[:, 'mean']].groupby(ID_COLS).mean()\n",
    "    \n",
    "    df_out.loc[:,idx[:,'mean']] = df_out.loc[:,idx[:,'mean']].groupby(ID_COLS).fillna(\n",
    "        method='ffill'\n",
    "    ).groupby(ID_COLS).fillna(icustay_means).fillna(0)\n",
    "    \n",
    "    df_out.loc[:, idx[:, 'count']] = (df.loc[:, idx[:, 'count']] > 0).astype(float)\n",
    "    df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
    "    \n",
    "    is_absent = (1 - df_out.loc[:, idx[:, 'mask']])\n",
    "    hours_of_absence = is_absent.cumsum()\n",
    "    time_since_measured = hours_of_absence - hours_of_absence[is_absent==0].fillna(method='ffill')\n",
    "    time_since_measured.rename(columns={'mask': 'time_since_measured'}, level='Aggregation Function', inplace=True)\n",
    "\n",
    "    df_out = pd.concat((df_out, time_since_measured), axis=1)\n",
    "    df_out.loc[:, idx[:, 'time_since_measured']] = df_out.loc[:, idx[:, 'time_since_measured']].fillna(100)\n",
    "    \n",
    "    df_out.sort_index(axis=1, inplace=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "Ys['los_3'] = Ys['los_icu'] > 3\n",
    "Ys['los_7'] = Ys['los_icu'] > 7\n",
    "Ys.drop(columns=['los_icu'], inplace=True)\n",
    "Ys.astype(float)\n",
    "\n",
    "lvl2, raw = [df[\n",
    "    (df.index.get_level_values('icustay_id').isin(set(Ys.index.get_level_values('icustay_id')))) &\n",
    "    (df.index.get_level_values('hours_in') < WINDOW_SIZE)\n",
    "] for df in (data_full_lvl2, data_full_raw)]\n",
    "\n",
    "raw.columns = raw.columns.droplevel(level=['label', 'LEVEL1', 'LEVEL2'])\n",
    "\n",
    "train_frac, dev_frac, test_frac = 0.7, 0.1, 0.2\n",
    "lvl2_subj_idx, raw_subj_idx, Ys_subj_idx = [df.index.get_level_values('subject_id') for df in (lvl2, raw, Ys)]\n",
    "lvl2_subjects = set(lvl2_subj_idx)\n",
    "assert lvl2_subjects == set(Ys_subj_idx), \"Subject ID pools differ!\"\n",
    "assert lvl2_subjects == set(raw_subj_idx), \"Subject ID pools differ!\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "subjects, N = np.random.permutation(list(lvl2_subjects)), len(lvl2_subjects)\n",
    "N_train, N_dev, N_test = int(train_frac * N), int(dev_frac * N), int(test_frac * N)\n",
    "train_subj = subjects[:N_train]\n",
    "dev_subj   = subjects[N_train:N_train + N_dev]\n",
    "test_subj  = subjects[N_train+N_dev:]\n",
    "\n",
    "[(lvl2_train, lvl2_dev, lvl2_test), (raw_train, raw_dev, raw_test), (Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (lvl2, raw, Ys)\n",
    "]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "lvl2_means, lvl2_stds = lvl2_train.loc[:, idx[:,'mean']].mean(axis=0), lvl2_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "raw_means, raw_stds = raw_train.loc[:, idx[:,'mean']].mean(axis=0), raw_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "\n",
    "lvl2_train.loc[:, idx[:,'mean']] = (lvl2_train.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_dev.loc[:, idx[:,'mean']] = (lvl2_dev.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_test.loc[:, idx[:,'mean']] = (lvl2_test.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "\n",
    "raw_train.loc[:, idx[:,'mean']] = (raw_train.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "raw_dev.loc[:, idx[:,'mean']] = (raw_dev.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "raw_test.loc[:, idx[:,'mean']] = (raw_test.loc[:, idx[:,'mean']] - raw_means)/raw_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test = [\n",
    "    simple_imputer(df) for df in (raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test)\n",
    "]\n",
    "raw_flat_train, raw_flat_dev, raw_flat_test, lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test = [\n",
    "    df.pivot_table(index=['subject_id', 'hadm_id', 'icustay_id'], columns=['hours_in']) for df in (\n",
    "        raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test\n",
    "    )\n",
    "]\n",
    "\n",
    "for df in lvl2_train, lvl2_dev, lvl2_test, raw_train, raw_dev, raw_test: assert not df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 15\n",
    "\n",
    "LR_dist = DictDist({\n",
    "    'C': Choice(np.geomspace(1e-3, 1e3, 10000)),\n",
    "    'penalty': Choice(['l1', 'l2']),\n",
    "    'solver': Choice(['liblinear', 'lbfgs']),\n",
    "    'max_iter': Choice([100, 500])\n",
    "})\n",
    "np.random.seed(SEED)\n",
    "LR_hyperparams_list = LR_dist.rvs(N)\n",
    "for i in range(N):\n",
    "    if LR_hyperparams_list[i]['solver'] == 'lbfgs': LR_hyperparams_list[i]['penalty'] = 'l2'\n",
    "\n",
    "RF_dist = DictDist({\n",
    "    'n_estimators': ss.randint(50, 500),\n",
    "    'max_depth': ss.randint(2, 10),\n",
    "    'min_samples_split': ss.randint(2, 75),\n",
    "    'min_samples_leaf': ss.randint(1, 50),\n",
    "})\n",
    "np.random.seed(SEED)\n",
    "RF_hyperparams_list = RF_dist.rvs(N)\n",
    "\n",
    "GRU_D_dist = DictDist({\n",
    "    'cell_size': ss.randint(50, 75),\n",
    "    'hidden_size': ss.randint(65, 95), \n",
    "    'learning_rate': ss.uniform(2e-3, 1e-1),\n",
    "    'num_epochs': ss.randint(15, 150),\n",
    "    'patience': ss.randint(3, 7),\n",
    "    'batch_size': ss.randint(35, 65),\n",
    "    'early_stop_frac': ss.uniform(0.05, 0.1),\n",
    "    'seed': ss.randint(1, 10000),\n",
    "})\n",
    "np.random.seed(SEED)\n",
    "GRU_D_hyperparams_list = GRU_D_dist.rvs(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_basic(model, hyperparams_list, X_flat_train, X_flat_dev, X_flat_test, target):\n",
    "    best_s, best_hyperparams = -np.Inf, None\n",
    "    for i, hyperparams in enumerate(hyperparams_list):\n",
    "        print(\"On sample %d / %d (hyperparams = %s)\" % (i+1, len(hyperparams_list), repr((hyperparams))))\n",
    "        M = model(**hyperparams)\n",
    "        M.fit(X_flat_train, Ys_train[target])\n",
    "        s = roc_auc_score(Ys_dev[target], M.predict_proba(X_flat_dev)[:, 1])\n",
    "        if s > best_s:\n",
    "            best_s, best_hyperparams = s, hyperparams\n",
    "            print(\"New Best Score: %.2f @ hyperparams = %s\" % (100*best_s, repr((best_hyperparams))))\n",
    "\n",
    "    return run_only_final(model, best_hyperparams, X_flat_train, X_flat_dev, X_flat_test, target)\n",
    "\n",
    "def run_only_final(model, best_hyperparams, X_flat_train, X_flat_dev, X_flat_test, target):\n",
    "    best_M = model(**best_hyperparams)\n",
    "    best_M.fit(pd.concat((X_flat_train, X_flat_dev)), pd.concat((Ys_train, Ys_dev))[target])\n",
    "    y_true  = Ys_test[target]\n",
    "    y_score = best_M.predict_proba(X_flat_test)[:, 1]\n",
    "    y_pred  = best_M.predict(X_flat_test)\n",
    "\n",
    "    auc   = roc_auc_score(y_true, y_score)\n",
    "    auprc = average_precision_score(y_true, y_score)\n",
    "    acc   = accuracy_score(y_true, y_pred)\n",
    "    F1    = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return best_M, best_hyperparams, auc, auprc, acc, F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS_PATH = '/scratch/mmd/extraction_baselines-sklearn.pkl'\n",
    "with open(RESULTS_PATH, mode='rb') as f: results = pickle.load(f)\n",
    "    \n",
    "RERUN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model, hyperparams_list in [\n",
    "    ('RF', RandomForestClassifier, RF_hyperparams_list), ('LR', LogisticRegression, LR_hyperparams_list)\n",
    "]:\n",
    "    if model_name not in results: results[model_name] = {}\n",
    "    for t in ['mort_icu', 'los_3']:\n",
    "        if t not in results[model_name]: results[model_name][t] = {}\n",
    "        for n, X_flat_train, X_flat_dev, X_flat_test in (\n",
    "            ('lvl2', lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test),\n",
    "            ('raw', raw_flat_train, raw_flat_dev, raw_flat_test)\n",
    "        ):\n",
    "            if n in results[model_name][t]:\n",
    "                print(\"Finished model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                if RERUN: \n",
    "                    h = results[model_name][t][n][1]\n",
    "                    results[model_name][t][n] = run_only_final(model, h, X_flat_train, X_flat_dev, X_flat_test, t)\n",
    "                    \n",
    "                    print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                    print(results[model_name][t][n][2:])\n",
    "\n",
    "                    with open(RESULTS_PATH, mode='wb') as f: pickle.dump(results, f)\n",
    "                continue\n",
    "                \n",
    "            print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            results[model_name][t][n] = run_basic(\n",
    "                model, hyperparams_list, X_flat_train, X_flat_dev, X_flat_test, t\n",
    "            )\n",
    "            print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(results[model_name][t][n][2:])\n",
    "            with open(RESULTS_PATH, mode='wb') as f: pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED+1)\n",
    "LR_hyperparams_list_2 = LR_dist.rvs(45)\n",
    "for i in range(45):\n",
    "    if LR_hyperparams_list_2[i]['solver'] == 'lbfgs': LR_hyperparams_list_2[i]['penalty'] = 'l2'\n",
    "\n",
    "results_2 = {}\n",
    "results_2_PATH = '/scratch/mmd/extraction_baselines-sklearn_LR_2_runs.pkl'\n",
    "\n",
    "for model_name, model, hyperparams_list in [\n",
    "#     ('RF', RandomForestClassifier, RF_hyperparams_list),\n",
    "    ('LR', LogisticRegression, LR_hyperparams_list_2)\n",
    "]:\n",
    "    if model_name not in results_2: results_2[model_name] = {}\n",
    "    for t in ['mort_icu', 'los_3']:\n",
    "        if t not in results_2[model_name]: results_2[model_name][t] = {}\n",
    "        for n, X_flat_train, X_flat_dev, X_flat_test in (\n",
    "            ('lvl2', lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test),\n",
    "#             ('raw', raw_flat_train, raw_flat_dev, raw_flat_test)\n",
    "        ):\n",
    "            if n in results_2[model_name][t]:\n",
    "                print(\"Finished model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                if RERUN: \n",
    "                    h = results_2[model_name][t][n][1]\n",
    "                    results_2[model_name][t][n] = run_only_final(model, h, X_flat_train, X_flat_dev, X_flat_test, t)\n",
    "                    \n",
    "                    print(\"Final results_2 for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                    print(results_2[model_name][t][n][2:])\n",
    "\n",
    "                    with open(results_2_PATH, mode='wb') as f: pickle.dump(results_2, f)\n",
    "                continue\n",
    "                \n",
    "            print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            results_2[model_name][t][n] = run_basic(\n",
    "                model, hyperparams_list, X_flat_train, X_flat_dev, X_flat_test, t\n",
    "            )\n",
    "            print(\"Final results_2 for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(results_2[model_name][t][n][2:])\n",
    "            with open(results_2_PATH, mode='wb') as f: pickle.dump(results_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model_name, model, hyperparams_list in [\n",
    "#     ('RF', RandomForestClassifier, RF_hyperparams_list),\n",
    "    ('LR', LogisticRegression, LR_hyperparams_list_2)\n",
    "]:\n",
    "    if model_name not in results_2: results_2[model_name] = {}\n",
    "    for t in ['mort_icu', 'los_3']:\n",
    "        if t not in results_2[model_name]: results_2[model_name][t] = {}\n",
    "        for n, X_flat_train, X_flat_dev, X_flat_test in (\n",
    "#             ('lvl2', lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test),\n",
    "            ('raw', raw_flat_train, raw_flat_dev, raw_flat_test),\n",
    "        ):\n",
    "            if n in results_2[model_name][t]:\n",
    "                print(\"Finished model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                if RERUN: \n",
    "                    h = results_2[model_name][t][n][1]\n",
    "                    results_2[model_name][t][n] = run_only_final(model, h, X_flat_train, X_flat_dev, X_flat_test, t)\n",
    "                    \n",
    "                    print(\"Final results_2 for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                    print(results_2[model_name][t][n][2:])\n",
    "\n",
    "                    with open(results_2_PATH, mode='wb') as f: pickle.dump(results_2, f)\n",
    "                continue\n",
    "                \n",
    "            print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            results_2[model_name][t][n] = run_basic(\n",
    "                model, hyperparams_list, X_flat_train, X_flat_dev, X_flat_test, t\n",
    "            )\n",
    "            print(\"Final results_2 for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(results_2[model_name][t][n][2:])\n",
    "            with open(results_2_PATH, mode='wb') as f: pickle.dump(results_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model_name, model, hyperparams_list in [\n",
    "    ('RF', RandomForestClassifier, RF_hyperparams_list), ('LR', LogisticRegression, LR_hyperparams_list)\n",
    "]:\n",
    "    if model_name not in results: results[model_name] = {}\n",
    "    for t in ['mort_hosp', 'los_7']:\n",
    "        if t not in results[model_name]: results[model_name][t] = {}\n",
    "        for n, X_flat_train, X_flat_dev, X_flat_test in (\n",
    "            ('lvl2', lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test),\n",
    "            ('raw', raw_flat_train, raw_flat_dev, raw_flat_test)\n",
    "        ):\n",
    "            if n in results[model_name][t]:\n",
    "                print(\"Finished model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                if RERUN: \n",
    "                    h = results[model_name][t][n][1]\n",
    "                    results[model_name][t][n] = run_only_final(model, h, X_flat_train, X_flat_dev, X_flat_test, t)\n",
    "                    \n",
    "                    print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                    print(results[model_name][t][n][2:])\n",
    "\n",
    "                    with open(RESULTS_PATH, mode='wb') as f: pickle.dump(results, f)\n",
    "                continue\n",
    "                \n",
    "            print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            results[model_name][t][n] = run_basic(\n",
    "                model, hyperparams_list, X_flat_train, X_flat_dev, X_flat_test, t\n",
    "            )\n",
    "            print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(results[model_name][t][n][2:])\n",
    "            with open(RESULTS_PATH, mode='wb') as f: pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
